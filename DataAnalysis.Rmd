---
title: "Data Analysis"
author: "Katerina, Remy and Helena"
date: "11/15/2019"
output: html_document
---
#Add 1 paragraph describing your data set and 1 paragraph outlining your proposed in-class and out-of-class methods.

The Dialect Survey uses a series of questions, including rhyming word pairs and vocabulary words, to explore the distribution of dialects in American. We have 122 survey responses from 47,472 people from different city, state and zip code areas. The majority of participants were from the east coast, and approximately a third of the particpants were in the 20-29 age range.

In this project, we would use these data to fit a KNN classification model showing predicted class membership at each location in the US based on dialect. Our explanatory variable is zipcode and response is dialect. In addition, our second analysis will be based on a topic we haven't learned in class such as, neural networks to help us cluster, classify and recognize patterns of the data.  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
dialect_survey<-read_csv("dialect_survey.csv")
zip_codes<-read_csv("zipcodes.csv")
library(tidyverse)
library(GGally)
install.packages("usmap")
library(usmap)

##dataset with only ID, state, city, zip code, and answer to lawyer question
lawyer_response<-dialect_survey[,c(1:4, 18)]

for(i in seq_len(ncol(lawyer_response))){
  print(names(lawyer_response)[i])
  print(sum(is.na(lawyer_response[[i]])))
}

##we examined whether there are missing values and found 3 pieces of missing data for state, and 537 for city. However, there are no missing data values for zip code. We will use zip code as our explanatory variable.

##cleaned up our data: got rid of city and ID
lawyer_response<-dialect_survey[,c(3, 4, 18)]

lawyer_response_cleaned<-mutate(lawyer_response, ZIP=substr(ZIP, 2, 6))
lawyer_response_cleaned

results<-left_join(x=lawyer_response_cleaned, y=zip_codes, by="ZIP", copy=FALSE)
results

map1<-plot_usmap(regions="state")+labs(title="US Map")+
  theme(panel.background = element_rect(color="black", fill="lightblue"))+geom_point(data=results, aes(x=LNG, y=LAT, fill=Q014), size=0.1)


                                                                                     #install.packages("ggmap")

#install.packages("sp")
#library(ggmap)

#library(sp)
#ggplot()+geom_map(data=results, map=us_map,aes(x=LAT, y=LNG, color=Q014),size=0.1, #color="red")+geom_point(data=results, aes (x=LAT, y=LNG), size=0.1, #color="steelblue")+coord_equal()+ggthemes::theme_map()



g <- list(
  scope = 'usa',
  projection = list(type = 'albers usa'),
  showland = TRUE,
  landcolor = toRGB("gray95"),
  subunitcolor = toRGB("gray85"),
  countrycolor = toRGB("gray85"),
  countrywidth = 0.5,
  subunitwidth = 0.5
)

p <- plot_geo(results, lat = ~lat, lon = ~long)  %>%
  add_markers(
    text = ~paste(airport, city, state, paste("Arrivals:", cnt), sep = "<br />"),
    color = ~cnt, symbol = I("square"), size = I(8), hoverinfo = "text"
  ) %>%
  colorbar(title = "Incoming flights<br />February 2011") %>%
  layout(
    title = 'Most trafficked US airports<br />(Hover for airport)', geo = g
  )



USA<-map_data("world") %>% filter(region=="USA")


# Libraries
library(ggplot2)
library(dplyr)
 
# Get the world polygon and extract UK
library(maps)
USA <- map_data("world") %>% filter(region=="USA")

# Get a data frame with longitude, latitude, and size of bubbles (a bubble = a city)
data <- world.cities %>% filter(country.etc=="USA")

# Left chart
g<-ggplot() +
  geom_polygon(data = USA, aes(x=long, y = lat, group = group), fill="grey") +
  geom_point(data=results, aes(x=LNG, y=LAT, color=Q014), size=0.1) +
  theme_void()+coord_map(xlim = c(-180, 180),ylim = c(18, 72))
g
```

##https://www.r-graph-gallery.com/330-bubble-map-with-ggplot2.html
